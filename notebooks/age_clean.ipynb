{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9425da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/census_data/2018_Data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get rid of specific columns\n",
    "pattern1 = r'Margin of Error'\n",
    "pattern2 = r'PERCENT ALLOCATED'\n",
    "pattern3 = r'Unnamed:'\n",
    "\n",
    "drop = []\n",
    "    \n",
    "for col in data.columns:\n",
    "    if (re.search(pattern1,col) or re.search(pattern2,col) or re.search(pattern3,col)):\n",
    "        drop.append(col)\n",
    "#end\n",
    "    \n",
    "data = data.drop(columns = drop)\n",
    "\n",
    "\n",
    "### clean up columns names\n",
    "new_cols = []\n",
    "\n",
    "for col in data.columns:\n",
    "    new_col = col.replace('Estimate','').replace('Total', '').replace('!!',' ').strip()\n",
    "    new_cols.append(new_col)\n",
    "#end\n",
    "    \n",
    "data.columns = new_cols\n",
    "\n",
    "\n",
    "### replace N and - with NaN\n",
    "data = data.replace(to_replace='N',value=np.nan).replace(to_replace = '-', value = np.nan).replace('**',np.nan)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd60c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'over.AGE'\n",
    "keep = ['Geographic Area Name', 'Workers 16 years and over', 'Workers 16 years and over who did not work at home',\n",
    "        'Car, truck, or van -- drove alone Workers 16 years and over', 'Car, truck, or van -- carpooled Workers 16 years and over',\n",
    "        'Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "\n",
    "for col in data.columns:\n",
    "    if re.search(pattern,col):\n",
    "        keep.append(col)\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc475a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = data[keep]\n",
    "#age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40038e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = age.dropna(thresh = 24)\n",
    "age = age.set_index('Geographic Area Name')\n",
    "#age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27930df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca37f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = age.apply(pd.to_numeric)\n",
    "age.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fdad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop = []\n",
    "for ind, values in age.iterrows():\n",
    "    if pd.isna(values['Workers 16 years and over who did not work at home']):\n",
    "        drop.append(ind)\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1026b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = age.drop(index = drop)\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205bfb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(age.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f34d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in age.itertuples():\n",
    "    comm_total  = row[2]\n",
    "    drove_alone = row[3]\n",
    "    carpool     = row[4]\n",
    "    pub_transit = row[5]\n",
    "\n",
    "    for i in range(6,34):\n",
    "        if i <= 11: # total\n",
    "            try:\n",
    "                new_val = int(comm_total*(row[i]/100))\n",
    "                age.loc[row.Index, age.columns[i-1]] = new_val\n",
    "            except:\n",
    "                age.loc[row.Index, age.columns[i-1]] = np.nan\n",
    "            #end\n",
    "        elif ((i >= 13) and (i <= 18)): # drove alone\n",
    "            try:\n",
    "                new_val = int(drove_alone*(row[i]/100))\n",
    "                age.loc[row.Index, age.columns[i-1]] = new_val\n",
    "            except:\n",
    "                age.loc[row.Index, age.columns[i-1]] = np.nan\n",
    "                #end\n",
    "        elif ((i >= 20) and (i <= 25)): # carpool\n",
    "            try:\n",
    "                new_val = int(carpool*(row[i]/100))\n",
    "                age.loc[row.Index, age.columns[i-1]] = new_val\n",
    "            except:\n",
    "                age.loc[row.Index, age.columns[i-1]] = np.nan\n",
    "            #end\n",
    "        elif ((i >= 27) and (i <= 32)): # public transit\n",
    "            try:\n",
    "                new_val = int(pub_transit*(row[i]/100))\n",
    "                age.loc[row.Index, age.columns[i-1]] = new_val\n",
    "            except:\n",
    "                age.loc[row.Index, age.columns[i-1]] = np.nan\n",
    "            #end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a146e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d04862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(path, category = 'AGE'):\n",
    "    ### read in data\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    \n",
    "    ### create name of file for saving\n",
    "    year = int(path.split('_data/')[1].split('_Data')[0])\n",
    "    file = str(year) + f'_Data_{str.capitalize(category)}'\n",
    "    \n",
    "    ### get rid of specific columns\n",
    "    #print('Get rid of specific columns')\n",
    "    pattern1 = r'Margin of Error'\n",
    "    pattern2 = r'PERCENT ALLOCATED'\n",
    "    pattern3 = r'Unnamed:'\n",
    "\n",
    "    drop = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if (re.search(pattern1,col) or re.search(pattern2,col) or re.search(pattern3,col)):\n",
    "            drop.append(col)\n",
    "    #end\n",
    "    \n",
    "    data = data.drop(columns = drop)\n",
    "    \n",
    "    ### clean up columns names\n",
    "    #print('Clean up columns names')\n",
    "    new_cols = []\n",
    "\n",
    "    for col in data.columns:\n",
    "        new_col = col.replace('Estimate','').replace('Total', '').replace('!!',' ').replace('  ',' ').strip()\n",
    "        new_cols.append(new_col)\n",
    "    #end\n",
    "    \n",
    "    data.columns = new_cols\n",
    "    \n",
    "    \n",
    "    ### replace N and - with NaN\n",
    "    #print('Replace N and - with NaN')\n",
    "    data = data.replace(to_replace='N',value=np.nan).replace(to_replace = '-', value = np.nan).replace('**',np.nan)\n",
    "    \n",
    "    \n",
    "    ### remove rows that are mostly null or where 'Workers 16 years and over who did not work from home' is null\n",
    "    ### ALSO CHECK IF THIS COLUMN EXISTS!\n",
    "    #print('Determine j')\n",
    "    data = data.dropna(thresh = 25)\n",
    "    \n",
    "    if 'Workers 16 years and over who did not work from home' in data.columns:\n",
    "        j = 1 # this indicates that my original code will work with this data\n",
    "        print('j is',j)\n",
    "        \n",
    "        drop = []\n",
    "        \n",
    "        for ind, values in data.iterrows():\n",
    "            if pd.isna(values['Workers 16 years and over who did not work from home']):\n",
    "                drop.append(ind)\n",
    "        #end\n",
    "\n",
    "    elif year == 2018:\n",
    "        j = 2\n",
    "        print('j is',j)\n",
    "        drop = []\n",
    "        \n",
    "        for ind, values in data.iterrows():\n",
    "            if pd.isna(values['Workers 16 years and over who did not work at home']):\n",
    "                drop.append(ind)\n",
    "        #end\n",
    "    \n",
    "    else:\n",
    "        j = 0\n",
    "        print('j is',j)\n",
    "        drop = []\n",
    "        \n",
    "        for ind, values in data.iterrows():\n",
    "            if pd.isna(values['Workers 16 years and over who did not work at home']):\n",
    "                drop.append(ind)\n",
    "        #end\n",
    "    \n",
    "    data = data.drop(index = drop)\n",
    "    \n",
    "    \n",
    "    ### keep specific commute related columns\n",
    "    #print('Keep specific commute related columns')\n",
    "\n",
    "    if j%2 == 0: # that is, j = 0 or j = 2\n",
    "        pattern1 = r'AGE.\\d'\n",
    "        pattern2 = r'Median age'\n",
    "    else:\n",
    "        pattern1 = r'over.AGE'\n",
    "        pattern2 = r'PLACEHOLDER TEXT' # There wasn't any need for a second pattern but I needed the code to be consistent\n",
    "    \n",
    "    if j%2 == 0:\n",
    "        keep = ['Geographic Area Name','Workers 16 years and over','Workers 16 years and over who did not work at home',\n",
    "                'Car, truck, or van -- drove alone Workers 16 years and over', 'Car, truck, or van -- carpooled Workers 16 years and over',\n",
    "                'Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "    else:\n",
    "        keep = ['Geographic Area Name','Workers 16 years and over','Workers 16 years and over who did not work from home',\n",
    "                'Car, truck, or van -- drove alone Workers 16 years and over','Car, truck, or van -- carpooled Workers 16 years and over',\n",
    "                'Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "        \n",
    "    for col in data.columns:\n",
    "        if re.search(pattern1,col) or re.search(pattern2,col):\n",
    "            keep.append(col)\n",
    "    #end\n",
    "    \n",
    "    data = data[keep]\n",
    "\n",
    "    \n",
    "    ### Set county as index\n",
    "    data = data.set_index('Geographic Area Name')\n",
    "    \n",
    "    \n",
    "    ### make dtypes numeric\n",
    "    data = data.apply(pd.to_numeric)\n",
    "    \n",
    "\n",
    "\n",
    "    ### get rid of percentages by translating them to integers BASED ON j\n",
    "    if j == 0:\n",
    "        for row in data.itertuples():\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "\n",
    "            for i in range(6,30):\n",
    "                if i%4 == 2: # total\n",
    "                    try:\n",
    "                        new_val = int(comm_total*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                elif i%4 == 3: # drove alone\n",
    "                    try:\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                        #end\n",
    "                elif i%4 == 0: # carpool\n",
    "                    try:\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                elif i%4 == 1: # public transit\n",
    "                    try:\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "    elif j == 1:\n",
    "        for row in data.itertuples():\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "            \n",
    "            for i in range(6,33):                \n",
    "                if (i <= 11): # total\n",
    "                    try:\n",
    "                        new_val = int(comm_total*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif ((i >= 13) and (i <= 18)): # drove alone\n",
    "                    try:\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                        #end\n",
    "                        \n",
    "                elif ((i >= 20) and (i <= 25)): # carpool\n",
    "                    try:\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif ((i >= 27) and (i <= 32)): # public transit\n",
    "                    try:\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "    else:\n",
    "        for row in data.itertuples():\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "            \n",
    "            for i in range(6,31):                \n",
    "                if (i < 12): # total\n",
    "                    try:\n",
    "                        new_val = int(comm_total*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif i == 12:\n",
    "                    continue\n",
    "                    \n",
    "                elif i%3 == 1: # drove alone\n",
    "                    try:\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                        #end\n",
    "                        \n",
    "                elif i%3 == 2: # carpool\n",
    "                    try:\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif i%3 == 0: # public transit\n",
    "                    try:\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "        #end\n",
    "    \n",
    "    \n",
    "    ### Clean up column names some more\n",
    "    pattern0 = r'Workers 16 years and over who did not work at home'\n",
    "    pattern1 = r'Workers 16 years and over who did not work from home'\n",
    "    pattern2 = r'Estimate'\n",
    "    pattern3 = r'(excluding taxicab)'\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for col in data.columns:\n",
    "        if (col != 'Workers 16 years and over who did not work from home' \n",
    "            and col != 'Workers 16 years and over who did not work from home') and (re.search(pattern1,col) \n",
    "                                                                                 or re.search(pattern2,col) \n",
    "                                                                                 or re.search(pattern3,col)):\n",
    "            new_col = col.replace(str(pattern1),'').replace(str(pattern2),'').replace(str(pattern3),'').strip()\n",
    "            new_cols[col] = new_col\n",
    "    #end\n",
    "    \n",
    "    data = data.rename(columns = new_cols)\n",
    "    data = data.dropna(thresh = 25)\n",
    "    \n",
    "    ### save county file\n",
    "    data.to_csv(f'../data/cleaned_data/{file}_County.csv')\n",
    "    \n",
    "    \n",
    "    ### set up aggregations for group by\n",
    "    aggs = {}\n",
    "    \n",
    "    for col in data.columns:        \n",
    "        num = data.columns.get_loc(col)\n",
    "        \n",
    "        if j == 0:\n",
    "            if num < 29:\n",
    "                aggs[col] = np.sum\n",
    "            else:\n",
    "                aggs[col] = np.median\n",
    "            #end\n",
    "        elif j == 1:\n",
    "            if num in [11,18,25,32]:\n",
    "                aggs[col] = np.median\n",
    "            else:\n",
    "                aggs[col] = np.sum\n",
    "            #end\n",
    "        elif j == 2:\n",
    "            if num in [11,30,31,32]:\n",
    "                aggs[col] = np.median\n",
    "            else:\n",
    "                aggs[col] = np.sum\n",
    "    #end\n",
    "    \n",
    "    \n",
    "    ### add State column (so we can group by it)\n",
    "    states = []\n",
    "\n",
    "    for ind, values in data.iterrows():\n",
    "        state = ind.split(', ')[1]\n",
    "        states.append(state)\n",
    "    #end\n",
    "    \n",
    "    data['State'] = states\n",
    "    \n",
    "    \n",
    "    ### finally, group by state and return df\n",
    "    \n",
    "    data = data.groupby('State').agg(aggs).replace(np.nan, 0).astype(int)#.replace(to_replace=0,value=np.nan)\n",
    "    \n",
    "    data.to_csv(f'../data/cleaned_data/{file}_State.csv')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e3d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = filter_data('../data/census_data/2021_Data.csv')\n",
    "df.loc[df['Public transportation  Workers 16 years and over'] > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e8424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns#['Public transportation Workers 16 years and over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac56097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Houston County, Alabama', 'Workers 16 years and over AGE 16 to 19 years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e20a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/census_data/2010_Data.csv')\n",
    "\n",
    "### get rid of specific columns\n",
    "pattern1 = r'Margin of Error'\n",
    "pattern2 = r'PERCENT ALLOCATED'\n",
    "pattern3 = r'Unnamed:'\n",
    "\n",
    "drop = []\n",
    "    \n",
    "for col in data.columns:\n",
    "    if (re.search(pattern1,col) or re.search(pattern2,col) or re.search(pattern3,col)):\n",
    "        drop.append(col)\n",
    "#end\n",
    "    \n",
    "data = data.drop(columns = drop)\n",
    "\n",
    "### clean up columns names\n",
    "new_cols = []\n",
    "\n",
    "for col in data.columns:\n",
    "    new_col = col.replace('Estimate','').replace('Total', '').replace('!!',' ').replace('  ',' ').strip()\n",
    "    new_cols.append(new_col)\n",
    "#end\n",
    "    \n",
    "data.columns = new_cols\n",
    "\n",
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc940f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern1 = r'AGE.\\d'\n",
    "pattern2 = r'Median age'\n",
    "\n",
    "keep = ['Geographic Area Name','Workers 16 years and over','Car, truck, or van -- drove alone Workers 16 years and over',\n",
    "        'Car, truck, or van -- carpooled Workers 16 years and over','Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "\n",
    "for col in data.columns:\n",
    "    if re.search(pattern,col) or re.search(pattern2,col):\n",
    "        print('KEEPING:',col)\n",
    "        keep.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb4629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[keep]\n",
    "data = data.replace('N',np.nan)\n",
    "data = data.dropna(thresh = 20)\n",
    "data = data.set_index('Geographic Area Name')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_data('../data/census_data/2021_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d3745",
   "metadata": {},
   "source": [
    "Now let's get everything for each table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980c445",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range (2010,2023):\n",
    "    if i != 2020:\n",
    "        print(i)\n",
    "        \n",
    "        try:\n",
    "            path = f'../data/census_data/{i}_Data.csv'\n",
    "            new_df = filter_data(path)\n",
    "            #new_df.to_csv(f'../data/cleaned_data/{i}_Data_State.csv')\n",
    "            print('Completed')\n",
    "        except:\n",
    "            print('Skipped')\n",
    "            continue\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d44c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
