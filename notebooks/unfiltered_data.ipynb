{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a72f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_commute(path):\n",
    "    ### read in data\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    ### create name of file for saving\n",
    "    year = int(path.split('_data/')[1].split('_Data')[0])\n",
    "    file = str(year) + '_commute'\n",
    "    \n",
    "               \n",
    "    ### get rid of specific columns\n",
    "    #print('Get rid of specific columns')\n",
    "    pattern1 = r'Margin of Error'\n",
    "    pattern2 = r'PERCENT ALLOCATED'\n",
    "    pattern3 = r'Unnamed:'\n",
    "\n",
    "    drop = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if (re.search(pattern1,col) or re.search(pattern2,col) or re.search(pattern3,col)):\n",
    "            drop.append(col)\n",
    "    #end\n",
    "    \n",
    "    data = data.drop(columns = drop)\n",
    "    \n",
    "    ### clean up columns names\n",
    "    #print('Clean up columns names')\n",
    "    new_cols = []\n",
    "\n",
    "    for col in data.columns:\n",
    "        new_col = col.replace('Estimate','').replace('Total', '').replace('!!',' ').replace('  ',' ').strip()\n",
    "        new_cols.append(new_col)\n",
    "    #end\n",
    "    \n",
    "    data.columns = new_cols\n",
    "    \n",
    "    \n",
    "    ### ALSO CHECK IF THIS COLUMN EXISTS!\n",
    "    #print('Determine j')\n",
    "    \n",
    "    if year > 2018:\n",
    "        j = 1 # this indicates that my original code will work with this data\n",
    "        #print('j is',j)\n",
    "\n",
    "    elif year == 2018:\n",
    "        j = 2\n",
    "        #print('j is',j)\n",
    "\n",
    "    else:\n",
    "        j = 0\n",
    "        #print('j is',j)\n",
    "\n",
    "    \n",
    "    ### keep specific commute related columns\n",
    "    #print('Keep specific commute related columns')\n",
    "    pattern1 = r'TRAVEL TIME'\n",
    "    \n",
    "    if j%2 == 0:\n",
    "        keep = ['Geographic Area Name','Workers 16 years and over','Workers 16 years and over who did not work at home',\n",
    "                'Car, truck, or van -- drove alone Workers 16 years and over','Car, truck, or van -- carpooled Workers 16 years and over',\n",
    "                'Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "    else:\n",
    "        keep = ['Geographic Area Name','Workers 16 years and over','Workers 16 years and over who did not work from home',\n",
    "                'Car, truck, or van -- drove alone Workers 16 years and over','Car, truck, or van -- carpooled Workers 16 years and over',\n",
    "                'Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if re.search(pattern1,col):\n",
    "            keep.append(col)\n",
    "    #end\n",
    "    \n",
    "    data = data[keep]\n",
    "\n",
    "    \n",
    "    ### Set county as index\n",
    "    #print('Set county as index')\n",
    "\n",
    "    data = data.set_index('Geographic Area Name')\n",
    "    \n",
    "    \n",
    "    ### replace N and - with NaN\n",
    "    #print('Replace N and - with NaN')\n",
    "    data = data.replace(to_replace='N',value=np.nan).replace(to_replace = '-', value = np.nan).replace('**',np.nan)\n",
    "    \n",
    "    data = data.dropna(thresh = 25)\n",
    "    \n",
    "    \n",
    "    ### make dtypes numeric\n",
    "    #print('Make df numeric')\n",
    "    data = data.apply(pd.to_numeric)\n",
    "    \n",
    "    \n",
    "    ### get rid of percentages by translating them to integers BASED ON j\n",
    "    if j == 0:\n",
    "        for row in data.itertuples():\n",
    "            #print('\\tROW IS NOW:\\t',row.Index)\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "\n",
    "            for i in range(6,42):\n",
    "                #print('i is',i)\n",
    "                if i%4 == 2: # total\n",
    "                    try:\n",
    "                        #print('--> COMM_TOTAL\\nCOMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                        new_val = int(comm_total*(row[i]/100))\n",
    "                        #print('CHECK:',comm_total,'times',row[i]/100,'equals',new_val)\n",
    "                        \n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                if i%4 == 3: # drove alone\n",
    "                    try:\n",
    "                        #print('--> DROVE_ALONE\\nCOMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        #print('CHECK:',drove_alone,'times',row[i]/100,'equals',new_val)\n",
    "                        \n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                if i%4 == 0: # carpool\n",
    "                    try:\n",
    "                        #print('--> CARPOOL\\nCOMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        #print('CHECK:',carpool,'times',row[i]/100,'equals',new_val)\n",
    "                        \n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                if i%4 == 1: # public transit\n",
    "                    try:\n",
    "                        #print('--> PUB_TRANSIT\\nCOMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        #print('CHECK:',pub_transit,'times',row[i]/100,'equals',new_val)\n",
    "                        \n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "            #end\n",
    "    elif j == 1:\n",
    "        for row in data.itertuples():\n",
    "            #print('ROW IS:',row.Index)\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "\n",
    "            for i in range(6,15):\n",
    "                #print('i is',i)\n",
    "                try:\n",
    "                    #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                    new_val = int(comm_total*(row[i]/100))\n",
    "                    #print('CHECK:',comm_total,'times',row[i]/100,'equals',new_val)\n",
    "                    \n",
    "                    data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                except:\n",
    "                    data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "\n",
    "\n",
    "            for i in range(16,25):\n",
    "                #print('i is',i)\n",
    "                try:\n",
    "                    #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                    new_val = int(drove_alone*(row[i]/100))\n",
    "                    #print('CHECK:',drove_alone,'times',row[i]/100,'equals',new_val)\n",
    "                    \n",
    "                    data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                except:\n",
    "                    data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "\n",
    "\n",
    "            for i in range(26,35):\n",
    "                #print('i is',i)\n",
    "                try:\n",
    "                    #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                    new_val = int(carpool*(row[i]/100))\n",
    "                    #print('CHECK:',carpool,'times',row[i]/100,'equals',new_val)\n",
    "                    \n",
    "                    data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                except:\n",
    "                    data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "\n",
    "\n",
    "            for i in range(36,45):\n",
    "                #print('i is',i)\n",
    "                try:\n",
    "                    #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                    new_val = int(pub_transit*(row[i]/100))\n",
    "                    #print('CHECK:',pub_transit,'times',row[i]/100,'equals',new_val)\n",
    "                    \n",
    "                    data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                except:\n",
    "                    data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "        #end\n",
    "    \n",
    "    else:\n",
    "        for row in data.itertuples():\n",
    "            #print('ROW IS:',row.Index)\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "\n",
    "            for i in range(6,15):\n",
    "                #print('i is',i)\n",
    "                try:\n",
    "                    #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                    new_val = int(comm_total*(row[i]/100))\n",
    "                    #print('CHECK:',comm_total,'times',row[i]/100,'equals',new_val)\n",
    "                    \n",
    "                    data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                except:\n",
    "                    data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "\n",
    "            i = 16\n",
    "            while i < 43:\n",
    "                #print('i is',i)\n",
    "                \n",
    "                if i%3 == 1: # drove alone\n",
    "                    try:\n",
    "                        #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        #print('CHECK:',drove_alone,'times',row[i]/100,'equals',new_val)\n",
    "\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "\n",
    "\n",
    "                if i%3 == 2: # carpool\n",
    "                    try:\n",
    "                        #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        #print('CHECK:',carpool,'times',row[i]/100,'equals',new_val)\n",
    "\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "\n",
    "\n",
    "                if i%3 == 0: # public transit\n",
    "                    try:\n",
    "                        #print('COMPARE:',row[i],'to',data.loc[row.Index, data.columns[i-1]])\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        #print('CHECK:',pub_transit,'times',row[i]/100,'equals',new_val)\n",
    "\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                #end\n",
    "                \n",
    "                i += 1\n",
    "        \n",
    "    \n",
    "    ### Clean up column names some more\n",
    "    pattern1 = r'Workers 16 years and over who did not work from home'\n",
    "    pattern0 = r'Workers 16 years and over who did not work at home'\n",
    "    pattern2 = r'Estimate'\n",
    "    pattern3 = r'(excluding taxicab)'\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for col in data.columns:\n",
    "        if (col != 'Workers 16 years and over who did not work from home' and\n",
    "            col != 'Workers 16 years and over who did not work at home') and (re.search(pattern0,col) \n",
    "                                                                              or re.search(pattern1,col) \n",
    "                                                                              or re.search(pattern2,col) \n",
    "                                                                              or re.search(pattern3,col)):\n",
    "            new_col = col.replace(str(pattern0),'').replace(str(pattern1),'').replace(str(pattern2),'').replace(str(pattern3),'').strip()\n",
    "            new_cols[col] = new_col\n",
    "    #end\n",
    "    \n",
    "    data = data.rename(columns = new_cols)\n",
    "    \n",
    "    ### save county file\n",
    "    data.to_csv(f'../data/unfiltered_data/{file}_county.csv')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7bec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_commute('../data/census_data/2010_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc04864",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2010,2023):\n",
    "    if i != 2020:\n",
    "        print(i)\n",
    "        \n",
    "        try:\n",
    "            path = f'../data/census_data/{i}_Data.csv'\n",
    "            clean_commute(path)\n",
    "            print('Completed')\n",
    "        except:\n",
    "            print('Skipped')\n",
    "            continue\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_age(path):\n",
    "    ### read in data\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    \n",
    "    ### create name of file for saving\n",
    "    year = int(path.split('_data/')[1].split('_Data')[0])\n",
    "    file = str(year) + f'_age'\n",
    "    \n",
    "    ### get rid of specific columns\n",
    "    #print('Get rid of specific columns')\n",
    "    pattern1 = r'Margin of Error'\n",
    "    pattern2 = r'PERCENT ALLOCATED'\n",
    "    pattern3 = r'Unnamed:'\n",
    "\n",
    "    drop = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if (re.search(pattern1,col) or re.search(pattern2,col) or re.search(pattern3,col)):\n",
    "            drop.append(col)\n",
    "    #end\n",
    "    \n",
    "    data = data.drop(columns = drop)\n",
    "    \n",
    "    ### clean up columns names\n",
    "    #print('Clean up columns names')\n",
    "    new_cols = []\n",
    "\n",
    "    for col in data.columns:\n",
    "        new_col = col.replace('Estimate','').replace('Total', '').replace('!!',' ').replace('  ',' ').strip()\n",
    "        new_cols.append(new_col)\n",
    "    #end\n",
    "    \n",
    "    data.columns = new_cols\n",
    "    \n",
    "    \n",
    "    ### replace N and - with NaN\n",
    "    #print('Replace N and - with NaN')\n",
    "    data = data.replace(to_replace='N',value=np.nan).replace(to_replace = '-', value = np.nan).replace('**',np.nan)\n",
    "    \n",
    "    \n",
    "    ### ALSO CHECK IF THIS COLUMN EXISTS!\n",
    "    #print('Determine j')\n",
    "    \n",
    "    if year > 2018:\n",
    "        j = 1 # this indicates that my original code will work with this data\n",
    "        #print('j is',j)\n",
    "        \n",
    "    elif year == 2018:\n",
    "        j = 2\n",
    "        #print('j is',j)\n",
    "    \n",
    "    else:\n",
    "        j = 0\n",
    "        #print('j is',j)\n",
    "    \n",
    "    \n",
    "    ### keep specific commute related columns\n",
    "    #print('Keep specific commute related columns')\n",
    "\n",
    "    if j%2 == 0: # that is, j = 0 or j = 2\n",
    "        pattern1 = r'AGE.\\d'\n",
    "        pattern2 = r'Median age'\n",
    "    else:\n",
    "        pattern1 = r'over.AGE'\n",
    "        pattern2 = r'PLACEHOLDER TEXT' # There wasn't any need for a second pattern but I needed the code to be consistent\n",
    "    \n",
    "    if j%2 == 0:\n",
    "        keep = ['Geographic Area Name','Workers 16 years and over','Workers 16 years and over who did not work at home',\n",
    "                'Car, truck, or van -- drove alone Workers 16 years and over', 'Car, truck, or van -- carpooled Workers 16 years and over',\n",
    "                'Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "    else:\n",
    "        keep = ['Geographic Area Name','Workers 16 years and over','Workers 16 years and over who did not work from home',\n",
    "                'Car, truck, or van -- drove alone Workers 16 years and over','Car, truck, or van -- carpooled Workers 16 years and over',\n",
    "                'Public transportation (excluding taxicab) Workers 16 years and over']\n",
    "        \n",
    "    for col in data.columns:\n",
    "        if re.search(pattern1,col) or re.search(pattern2,col):\n",
    "            keep.append(col)\n",
    "    #end\n",
    "    \n",
    "    data = data[keep]\n",
    "\n",
    "    \n",
    "    ### Set county as index\n",
    "    data = data.set_index('Geographic Area Name')\n",
    "    \n",
    "    \n",
    "    ### make dtypes numeric\n",
    "    data = data.apply(pd.to_numeric)\n",
    "    \n",
    "\n",
    "\n",
    "    ### get rid of percentages by translating them to integers BASED ON j\n",
    "    if j == 0:\n",
    "        for row in data.itertuples():\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "\n",
    "            for i in range(6,30):\n",
    "                if i%4 == 2: # total\n",
    "                    try:\n",
    "                        new_val = int(comm_total*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                elif i%4 == 3: # drove alone\n",
    "                    try:\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                        #end\n",
    "                elif i%4 == 0: # carpool\n",
    "                    try:\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                elif i%4 == 1: # public transit\n",
    "                    try:\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "    elif j == 1:\n",
    "        for row in data.itertuples():\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "            \n",
    "            for i in range(6,33):                \n",
    "                if (i <= 11): # total\n",
    "                    try:\n",
    "                        new_val = int(comm_total*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif ((i >= 13) and (i <= 18)): # drove alone\n",
    "                    try:\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                        #end\n",
    "                        \n",
    "                elif ((i >= 20) and (i <= 25)): # carpool\n",
    "                    try:\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif ((i >= 27) and (i <= 32)): # public transit\n",
    "                    try:\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "    else:\n",
    "        for row in data.itertuples():\n",
    "            comm_total  = row[2]\n",
    "            drove_alone = row[3]\n",
    "            carpool     = row[4]\n",
    "            pub_transit = row[5]\n",
    "            \n",
    "            for i in range(6,31):                \n",
    "                if (i < 12): # total\n",
    "                    try:\n",
    "                        new_val = int(comm_total*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif i == 12:\n",
    "                    continue\n",
    "                    \n",
    "                elif i%3 == 1: # drove alone\n",
    "                    try:\n",
    "                        new_val = int(drove_alone*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                        #end\n",
    "                        \n",
    "                elif i%3 == 2: # carpool\n",
    "                    try:\n",
    "                        new_val = int(carpool*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "                    \n",
    "                elif i%3 == 0: # public transit\n",
    "                    try:\n",
    "                        new_val = int(pub_transit*(row[i]/100))\n",
    "                        data.loc[row.Index, data.columns[i-1]] = new_val\n",
    "\n",
    "                    except:\n",
    "                        data.loc[row.Index, data.columns[i-1]] = np.nan\n",
    "                    #end\n",
    "        #end\n",
    "    \n",
    "    \n",
    "    ### Clean up column names some more\n",
    "    pattern0 = r'Workers 16 years and over who did not work at home'\n",
    "    pattern1 = r'Workers 16 years and over who did not work from home'\n",
    "    pattern2 = r'Estimate'\n",
    "    pattern3 = r'(excluding taxicab)'\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    for col in data.columns:\n",
    "        if (col != 'Workers 16 years and over who did not work from home' \n",
    "            and col != 'Workers 16 years and over who did not work from home') and (re.search(pattern1,col) \n",
    "                                                                                 or re.search(pattern2,col) \n",
    "                                                                                 or re.search(pattern3,col)):\n",
    "            new_col = col.replace(str(pattern1),'').replace(str(pattern2),'').replace(str(pattern3),'').strip()\n",
    "            new_cols[col] = new_col\n",
    "    #end\n",
    "    \n",
    "    data = data.rename(columns = new_cols)\n",
    "    \n",
    "    ### save county file\n",
    "    data.to_csv(f'../data/unfiltered_data/{file}_county.csv')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2010,2023):\n",
    "    if i != 2020:\n",
    "        print(i)\n",
    "        \n",
    "        try:\n",
    "            path = f'../data/census_data/{i}_Data.csv'\n",
    "            clean_age(path)\n",
    "            print('Completed')\n",
    "        except:\n",
    "            print('Skipped')\n",
    "            continue\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e507420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure(path):\n",
    "    df = pd.read_csv(path)\n",
    "    year = int(path.split('_data/')[1].split('_')[0])\n",
    "    csv_type = path.split(str(year)[1].split('_county')[0])\n",
    "    \n",
    "    if csv_type == 'commute':\n",
    "        csv_type = 'comm'\n",
    "    \n",
    "    \n",
    "    ### set county as index\n",
    "    df = df.set_index('Geographic Area Name')\n",
    "    \n",
    "    \n",
    "    ### drop total column since we're only interested in people who travel\n",
    "    df = df.drop(columns = 'Workers 16 years and over')\n",
    "        \n",
    "    \n",
    "    ### change column names\n",
    "    new_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == 'Workers 16 years and over who did not work from home' or col == 'Workers 16 years and over who did not work at home':\n",
    "            #print('FOUND')\n",
    "            new_col = 'workers'\n",
    "            new_cols.append(new_col)\n",
    "        \n",
    "        else:\n",
    "            # The great replacening\n",
    "            new_col = str.lower(col)\n",
    "            new_col = new_col.replace(' 16 years and over','').replace('car, truck, or van -- ','').strip()\n",
    "            new_col = new_col.replace('travel time to work ','').replace(' to ','_').replace('less than ','').strip()\n",
    "            new_col = new_col.replace('-work (minutes)','').replace(' or more','').strip()\n",
    "            new_col = new_col.replace('public transportation','pub_transit').replace(' workers','').replace('minutes','min').strip()\n",
    "            new_col = new_col.replace('(years)','').replace(' years','').replace('  ',' ').strip().replace(' ','_')\n",
    "            new_col = new_col.replace('__','_').replace('_who_did_not_work_at_home','').replace('_who_did_not_work_from_home','')\n",
    "            if year >= 2018:\n",
    "                new_col = new_col.replace('age_median','median')\n",
    "            #end\n",
    "            new_col = new_col.replace('(min)','min')\n",
    "            new_col = re.sub(r'workers_(\\d)',r'\\1',new_col)\n",
    "            new_col = new_col.replace('workers_mean','mean').replace('workers_age','age').replace('workers_median','median')\n",
    "            new_cols.append(new_col)\n",
    "        #end\n",
    "    \n",
    "    df.columns = new_cols\n",
    "    \n",
    "    \n",
    "    ### change index name\n",
    "    df.index.name = 'county_name'\n",
    "    \n",
    "    \n",
    "    ### add percentage columns\n",
    "    df['alone_pct']   = round( (df['drove_alone'] / df['workers']) * 100, 2)\n",
    "    df['carpool_pct'] = round( (df['carpooled'] / df['workers']) * 100, 2)\n",
    "    df['transit_pct'] = round( (df['pub_transit'] / df['workers']) * 100, 2)\n",
    "    \n",
    "    \n",
    "    ### add state and year columns\n",
    "    states = []\n",
    "    counties = []\n",
    "    \n",
    "    for county_name in df.index:\n",
    "        split = county_name.split(', ')\n",
    "        state = split[1]\n",
    "        county = split[0]\n",
    "        states.append(state)\n",
    "        counties.append(county)\n",
    "    #end\n",
    "    \n",
    "    df['state'] = states\n",
    "    df['county'] = counties\n",
    "    df['year'] = year\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576ab18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "configure('../data/unfiltered_data/2010_commute_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4949434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = ['commute','age']\n",
    "df_dict = {}\n",
    "\n",
    "for cat in categories:\n",
    "    df = pd.DataFrame()\n",
    "    print('RESET DF')\n",
    "    \n",
    "    for i in range(2010,2023):\n",
    "        if i != 2020:\n",
    "            print(cat,i,len(df.index))\n",
    "            path = f'../data/unfiltered_data/{i}_{cat}_county.csv'\n",
    "            subset = configure(path)\n",
    "            df = pd.concat([df,subset])\n",
    "            print(len(df.index))\n",
    "        #end\n",
    "    \n",
    "    df_dict[cat] = df\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = df_dict['commute']\n",
    "comm.to_csv('../data/unfiltered_data/comm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d21999",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = df_dict['age']\n",
    "age.to_csv('../data/unfiltered_data/age.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f325316",
   "metadata": {},
   "outputs": [],
   "source": [
    "age.loc[age.year == 2022]['workers'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e55c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_year = age.groupby('year')['workers'].sum().to_frame()\n",
    "work_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = work_year.index, y = work_year.workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33bc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
